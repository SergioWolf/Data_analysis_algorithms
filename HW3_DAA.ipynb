{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Классификация. Логистическая регрессия"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "X = np.array([ [   1,    1,  500,    1],\n",
    "               [   1,    1,  700,    1],\n",
    "               [   1,    2,  750,    2],\n",
    "               [   1,    5,  600,    1],\n",
    "               [   1,    3, 1450,    2],\n",
    "               [   1,    0,  800,    1],\n",
    "               [   1,    5, 1500,    3],\n",
    "               [   1,   10, 2000,    3],\n",
    "               [   1,    1,  450,    1],\n",
    "               [   1,    2, 1000,    2]], dtype = np.float64)\n",
    "\n",
    "y = np.array([0, 0, 1, 0, 1, 0, 1, 0, 1, 1], dtype = np.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standard_scale(x):\n",
    "    res = (x - x.mean()) / x.std()\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.        ,  1.        , -0.97958969,  1.        ],\n",
       "       [ 1.        ,  1.        , -0.56713087,  1.        ],\n",
       "       [ 1.        ,  2.        , -0.46401617,  2.        ],\n",
       "       [ 1.        ,  5.        , -0.77336028,  1.        ],\n",
       "       [ 1.        ,  3.        ,  0.97958969,  2.        ],\n",
       "       [ 1.        ,  0.        , -0.36090146,  1.        ],\n",
       "       [ 1.        ,  5.        ,  1.08270439,  3.        ],\n",
       "       [ 1.        , 10.        ,  2.11385144,  3.        ],\n",
       "       [ 1.        ,  1.        , -1.08270439,  1.        ],\n",
       "       [ 1.        ,  2.        ,  0.05155735,  2.        ]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_st = X.copy()\n",
    "X_st[:, 2] = standard_scale(X[:, 2])\n",
    "\n",
    "X_st"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1. *Измените функцию calc_logloss так, чтобы нули по возможности не попадали в np.log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_logloss(y, y_pred):\n",
    "    pred_log1 = np.array([0 if x == 0 else np.log(x) for x in y_pred])\n",
    "    pred_log2 = np.array([0 if x == 1 else np.log(1.0 - x) for x in y_pred])\n",
    "    err = - np.mean(y * pred_log1 + (1.0 - y) * pred_log2)\n",
    "    return err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.05268025782891314"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Плохой пример применения\n",
    "y1 = np.array([1, 0])\n",
    "y_pred1 = np.array([1, 0.1])\n",
    "calc_logloss(y1, y_pred1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2. Подберите аргументы функции eval_model для логистической регрессии таким образом, чтобы log loss был минимальным"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    res = 1 / (1 + np.exp(-z))\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_model(X, y, iterations, eta=1e-4):\n",
    "    np.random.seed(42)\n",
    "    W = np.random.randn(X.shape[1])\n",
    "    n = X.shape[0]\n",
    "    \n",
    "    for i in range(iterations):\n",
    "        z = np.dot(X, W)\n",
    "        y_pred = sigmoid(z)\n",
    "        err = calc_logloss(y, y_pred)\n",
    "        \n",
    "        dQ = 1/n * X.T @ (y_pred - y)\n",
    "        W -= eta * dQ\n",
    "        if i % (iterations / 10) == 0:\n",
    "            print(i, W, err)n\n",
    "    return W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [ 0.45877546 -0.2833519   0.6449505   1.46641523] 1.1785958344356262\n",
      "10000 [-10.74518967  -1.38402525  -2.42101957   9.13461388] 0.2321387488434184\n",
      "20000 [-15.42754617  -1.78141273  -3.82881206  12.91762302] 0.19343207615808586\n",
      "30000 [-19.03214673  -2.10018205  -4.88462075  15.84722845] 0.1705495036750294\n",
      "40000 [-21.99898567  -2.36617547  -5.74184132  18.25923693] 0.15508406003773303\n",
      "50000 [-24.52678352  -2.59425824  -6.4658027   20.31294088] 0.14388003971456603\n",
      "60000 [-26.7341771   -2.79398809  -7.09424451  22.10455082] 0.13535136053673655\n",
      "70000 [-28.69854717  -2.9718268   -7.6512386   23.6970608 ] 0.12860785839125297\n",
      "80000 [-30.4730121   -3.13231139  -8.1530329   25.13378696] 0.12311312476808871\n",
      "90000 [-32.09545327  -3.27872995  -8.61106042  26.44564896] 0.1185257929395436\n"
     ]
    }
   ],
   "source": [
    "W = eval_model(X_st, y, iterations=100000, eta=1e-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3. Создайте функцию calc_pred_proba, возвращающую предсказанную вероятность класса 1 (на вход подаются W, который уже посчитан функцией eval_model и X, на выходе - массив y_pred_proba)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_pred_proba(W, X):\n",
    "    z = np.dot(X, W)\n",
    "    y_pred_proba = sigmoid(z)\n",
    "    return y_pred_proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3.76929484e-01, 1.43636180e-02, 9.99999995e-01, 1.10343509e-07,\n",
       "       9.32592337e-01, 6.42801817e-02, 1.00000000e+00, 2.06617132e-02,\n",
       "       6.05609842e-01, 9.99999456e-01])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_proba = calc_pred_proba(W, X_st)\n",
    "y_pred_proba"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4. Создайте функцию calc_pred, возвращающую предсказанный класс (на вход подаются W, который уже посчитан функцией eval_model и X, на выходе - массив y_pred)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_pred(W, X):\n",
    "    return np.array([1 if x > 0.5 else 0 for x in calc_pred_proba(W, X)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, 0, 1, 0, 1, 0, 1, 1])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = calc_pred(W, X_st)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 5. *Реализуйте функции для подсчета Accuracy, матрицы ошибок, точности и полноты, а также F1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assessment_classification_quality(y, y_pred):\n",
    "    accuracy = np.sum([1 if t[0] == t[1] else 0 for t in zip(y, y_pred)]) / len(y)\n",
    "    print(f'accuracy = {accuracy}')\n",
    "    \n",
    "    tp = sum([1 if t[0] == t[1] == 1 else 0 for t in zip(y, y_pred)])\n",
    "    tn = sum([1 if t[0] == t[1] == 0 else 0 for t in zip(y, y_pred)])\n",
    "    fp = sum([1 if t[0] == 1 and t[1] == 0 else 0 for t in zip(y, y_pred)])\n",
    "    fn = sum([1 if t[0] == 0 and t[1] == 1 else 0 for t in zip(y, y_pred)])\n",
    "    print('Confustion matrix')\n",
    "    print('\\t1\\t0')\n",
    "    print(f'1\\t{tp}\\t{fp}')\n",
    "    print(f'0\\t{fn}\\t{tn}')\n",
    "    \n",
    "    precision = tp / (tp + fp)\n",
    "    print(f'precision = {precision}')\n",
    "    \n",
    "    recall = tp / (tp + fn)\n",
    "    print(f'recall = {recall}')\n",
    "    \n",
    "    F = 2 * precision * recall / (precision + recall)\n",
    "    print(f'F = {F}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy = 1.0\n",
      "Confustion matrix\n",
      "\t1\t0\n",
      "1\t5\t0\n",
      "0\t0\t5\n",
      "precision = 1.0\n",
      "recall = 1.0\n",
      "F = 1.0\n"
     ]
    }
   ],
   "source": [
    "assessment_classification_quality(y, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 6. Могла ли модель переобучиться? Почему?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Модель могла переобучиться, так как в датасете слишком мало наблюдений"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
